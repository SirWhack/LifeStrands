{
  "permissions": {
    "allow": [
      "Bash(mkdir:*)",
      "WebFetch(domain:docs.anthropic.com)",
      "Bash(make:*)",
      "Bash(sudo systemctl status:*)",
      "Bash(docker:*)",
      "Bash(getent:*)",
      "Bash(claude doctor)",
      "Bash(claude --version)",
      "Bash(rmdir:*)",
      "Bash(echo:*)",
      "Bash(curl:*)",
      "Bash(grep:*)",
      "Bash(pip show:*)",
      "Bash(lspci:*)",
      "Bash(apt list:*)",
      "Bash(./check_rocm.bat)",
      "Bash(python test:*)",
      "Bash(python3:*)",
      "Bash(ss:*)",
      "Bash(ip route:*)",
      "Bash(timeout:*)",
      "Bash(pip uninstall:*)",
      "Bash(pip --version)",
      "Bash(pip3:*)",
      "Bash(source:*)",
      "Bash(rocm_env/Scripts/python -m pip list:*)",
      "Bash(./rocm_env/Scripts/activate)",
      "Bash(./rocm_env/Scripts/python.exe -m pip list)",
      "Bash(./rocm_env/Scripts/python.exe -m pip install llama-cpp-python --force-reinstall --no-cache-dir --verbose)",
      "Bash(CMAKE_ARGS=\"-DGGML_VULKAN=ON\" ./rocm_env/Scripts/python.exe -m pip install llama-cpp-python --force-reinstall --no-cache-dir --verbose)",
      "Bash(vulkaninfo:*)",
      "Bash(./rocm_env/Scripts/python.exe -m pip install llama-cpp-python --force-reinstall --no-cache-dir)",
      "Bash(./rocm_env/Scripts/python.exe test_gpu.py)",
      "Bash(where vulkaninfo)",
      "WebFetch(domain:www.lunarg.com)",
      "Bash(./check_vulkan.bat)",
      "Bash(./rocm_env/Scripts/python.exe -m pip uninstall llama-cpp-python -y)",
      "Bash(./rocm_env/Scripts/python.exe test_gpu_load.py)",
      "Bash(mv:*)",
      "Bash(chmod:*)",
      "Bash(powershell.exe:*)"
    ],
    "deny": []
  }
}